# scopenizer-tokenizer



A tokenizer written purely in Go... which also can find scope!




## Motivation

This project's main goal is to combine the tasks
of finding the tokens within a programming language along with
distinguishing where scopes begin/end. Despite this being the
goal, the scopenizer tokenizer can be utilized for other parsing type tasks.



## Installation

```
TODO
```



## Usage





## LICENSE

MIT License

[See License](https://github.com/mccoyJosh/scopenizer-tokenizer/blob/main/LICENSE)
